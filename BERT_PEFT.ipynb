{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Alejandro Paredes, Parameter tunning of BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwAV24NJ-ZSj",
        "outputId": "f707f622-fcd8-4645-fc3f-6beaef291c8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting peft\n",
            "  Downloading peft-0.13.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from transformers) (3.16.0)\n",
            "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
            "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from transformers) (2024.7.24)\n",
            "Requirement already satisfied: requests in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Collecting safetensors>=0.4.1 (from transformers)\n",
            "  Downloading safetensors-0.4.5-cp39-none-win_amd64.whl.metadata (3.9 kB)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
            "  Downloading tokenizers-0.20.0-cp39-none-win_amd64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from transformers) (4.66.5)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp39-cp39-win_amd64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp39-cp39-win_amd64.whl.metadata (13 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.17-py39-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.10.9-cp39-cp39-win_amd64.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: psutil in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from peft) (6.0.0)\n",
            "Requirement already satisfied: torch>=1.13.0 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from peft) (2.4.1+cu118)\n",
            "Collecting accelerate>=0.21.0 (from peft)\n",
            "  Downloading accelerate-1.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
            "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.4.1-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.1.0-cp39-cp39-win_amd64.whl.metadata (5.1 kB)\n",
            "Collecting yarl<2.0,>=1.12.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.14.0-cp39-cp39-win_amd64.whl.metadata (54 kB)\n",
            "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: sympy in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from torch>=1.13.0->peft) (1.13.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from torch>=1.13.0->peft) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from pandas->datasets) (2.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->datasets)\n",
            "  Downloading propcache-0.2.0-cp39-cp39-win_amd64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\alejandro\\documents\\5. programming\\.virtualenvs\\aplt_duke\\lib\\site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
            "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
            "   --------------- ------------------------ 3.9/9.9 MB 21.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  9.7/9.9 MB 25.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 9.9/9.9 MB 23.7 MB/s eta 0:00:00\n",
            "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "Downloading peft-0.13.1-py3-none-any.whl (320 kB)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "Downloading accelerate-1.0.0-py3-none-any.whl (330 kB)\n",
            "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "Downloading aiohttp-3.10.9-cp39-cp39-win_amd64.whl (382 kB)\n",
            "Downloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
            "Downloading pyarrow-17.0.0-cp39-cp39-win_amd64.whl (25.1 MB)\n",
            "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
            "   -------- ------------------------------- 5.2/25.1 MB 24.5 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 11.3/25.1 MB 27.1 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 16.0/25.1 MB 25.8 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 21.2/25.1 MB 25.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.9/25.1 MB 24.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 25.1/25.1 MB 23.8 MB/s eta 0:00:00\n",
            "Downloading safetensors-0.4.5-cp39-none-win_amd64.whl (286 kB)\n",
            "Downloading tokenizers-0.20.0-cp39-none-win_amd64.whl (2.3 MB)\n",
            "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.3/2.3 MB 33.3 MB/s eta 0:00:00\n",
            "Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
            "Downloading xxhash-3.5.0-cp39-cp39-win_amd64.whl (30 kB)\n",
            "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
            "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading frozenlist-1.4.1-cp39-cp39-win_amd64.whl (50 kB)\n",
            "Downloading multidict-6.1.0-cp39-cp39-win_amd64.whl (28 kB)\n",
            "Downloading yarl-1.14.0-cp39-cp39-win_amd64.whl (84 kB)\n",
            "Downloading propcache-0.2.0-cp39-cp39-win_amd64.whl (45 kB)\n",
            "Installing collected packages: xxhash, safetensors, pyarrow, propcache, multiprocess, multidict, fsspec, frozenlist, async-timeout, aiohappyeyeballs, yarl, huggingface-hub, aiosignal, tokenizers, aiohttp, accelerate, transformers, peft, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.9.0\n",
            "    Uninstalling fsspec-2024.9.0:\n",
            "      Successfully uninstalled fsspec-2024.9.0\n",
            "Successfully installed accelerate-1.0.0 aiohappyeyeballs-2.4.3 aiohttp-3.10.9 aiosignal-1.3.1 async-timeout-4.0.3 datasets-3.0.1 evaluate-0.4.3 frozenlist-1.4.1 fsspec-2024.6.1 huggingface-hub-0.25.2 multidict-6.1.0 multiprocess-0.70.16 peft-0.13.1 propcache-0.2.0 pyarrow-17.0.0 safetensors-0.4.5 tokenizers-0.20.0 transformers-4.45.2 xxhash-3.5.0 yarl-1.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets peft evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C2gg1Syx-s44"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict, Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
        "import evaluate\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KfUh_vrS_hbR"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a3ba9173a204655bad5373291c3e16a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ALEJANDRO\\Documents\\5. Programming\\.virtualenvs\\aplt_duke\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ALEJANDRO\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c5d15aa1e484745bb4c54aa50295ab5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_checkpoint = 'distilbert-base-uncased'\n",
        "\n",
        "#Define label maps\n",
        "id2label = {0: \"Negative\", 1: \"Positive\"}\n",
        "label2id = {\"Negative\": 0, \"Positive\": 1}\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Yrj-hSULAi_a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77f15121fab544d3951317e4defeafed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/592 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ALEJANDRO\\Documents\\5. Programming\\.virtualenvs\\aplt_duke\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ALEJANDRO\\.cache\\huggingface\\hub\\datasets--shawhin--imdb-truncated. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cced1f9d7911408f8a15ff0500fe443f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "(…)-00000-of-00001-5a744bf76a1d84b2.parquet:   0%|          | 0.00/836k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4afb232e91549199675293f0834ac12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "(…)-00000-of-00001-a3a52fabb70c739f.parquet:   0%|          | 0.00/853k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9575b615c1b9495a87d75082fd498e18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aca9645d5c544ea4b5595d618ddcc301",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset('shawhin/imdb-truncated')\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vKd0MpK9BFPv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5134c0138a3a42e897e980717bb8de75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83f88bb034ba4fe98ed865c25f9cf0db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ce184d3454e42e7b149974e4b8abbba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ERySJZcQBp9_"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(examples):\n",
        "  text = examples[\"text\"]\n",
        "\n",
        "  tokenizer.truncation_side = \"left\"\n",
        "  tokenized_inputs = tokenizer(\n",
        "      text,\n",
        "      return_tensors = \"np\",\n",
        "      truncation = True,\n",
        "      max_length = 512\n",
        "  )\n",
        "\n",
        "  return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YmGXgdNQCb7e"
      },
      "outputs": [],
      "source": [
        "if tokenizer.pad_token is None:\n",
        "  tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "  model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZgXdBTYUDLz6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f89fb19f6de425cad9bb20a7d66ac3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "898fe570cc044e43b9e0e4c95b21955d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IjSOWH6wDNHw"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KJvaBgtkD963"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93d410fc9bc54dae8270649e9d7952b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "  predictions, labels = p\n",
        "  predictions = np.argmax(predictions, axis=1)\n",
        "  return {\"accuracy\": accuracy.compute(predictions=predictions\n",
        "                                       , references=labels)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6nP1LQquEmt2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Untrained model\n",
            "It was good. - Positive\n",
            "Not a fan, don't recommended - Negative\n",
            "Better than the first one. - Negative\n"
          ]
        }
      ],
      "source": [
        "text_list = [\"It was good.\", \"Not a fan, don't recommended\",\n",
        "              \"Better than the first one.\"]\n",
        "\n",
        "print(\"Untrained model\")\n",
        "for text in text_list:\n",
        "  inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "  logits = model(inputs).logits\n",
        "  predictions = torch.argmax(logits)\n",
        "  print(f'{text} - {id2label[predictions.tolist()]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8xiaVnUaF1Yf"
      },
      "outputs": [],
      "source": [
        "peft_config = LoraConfig(task_type='SEQ_CLS',\n",
        "                         r = 4,\n",
        "                         lora_alpha=32,\n",
        "                         lora_dropout=0.01,\n",
        "                         target_modules = ['q_lin'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "o4hduUwTGnN5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 628,994 || all params: 67,584,004 || trainable%: 0.9307\n"
          ]
        }
      ],
      "source": [
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3ORBVjXnGx19"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ALEJANDRO\\Documents\\5. Programming\\.virtualenvs\\aplt_duke\\lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "lr = 1e-3\n",
        "batch_size = 4\n",
        "num_epochs = 5\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"\"+model_checkpoint+\"lora-txt\",\n",
        "    learning_rate = lr,\n",
        "    per_device_train_batch_size = batch_size,\n",
        "    per_device_eval_batch_size = batch_size,\n",
        "    num_train_epochs = num_epochs,\n",
        "    weight_decay = 0.01,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    load_best_model_at_end = True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hmS4TS65IDDV"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = tokenized_dataset[\"train\"],\n",
        "    eval_dataset = tokenized_dataset[\"validation\"],\n",
        "    tokenizer = tokenizer,\n",
        "    data_collator = data_collator,\n",
        "    compute_metrics = compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gfzk-YnMJL0V"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "641515d4579243a5863bfc908b9daa49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5338777121854036838202862fe02320",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4470183849334717, 'eval_accuracy': {'accuracy': 0.865}, 'eval_runtime': 20.3094, 'eval_samples_per_second': 49.238, 'eval_steps_per_second': 12.31, 'epoch': 1.0}\n",
            "{'loss': 0.4357, 'grad_norm': 25.799226760864258, 'learning_rate': 0.0006, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9509cc7f258f4b8e966fc528a911e273",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.625886082649231, 'eval_accuracy': {'accuracy': 0.857}, 'eval_runtime': 20.5779, 'eval_samples_per_second': 48.596, 'eval_steps_per_second': 12.149, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98257acb2d3d4f2ead36e39b7f15e772",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6092552542686462, 'eval_accuracy': {'accuracy': 0.881}, 'eval_runtime': 20.8459, 'eval_samples_per_second': 47.971, 'eval_steps_per_second': 11.993, 'epoch': 3.0}\n",
            "{'loss': 0.152, 'grad_norm': 0.0035869302228093147, 'learning_rate': 0.0002, 'epoch': 4.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c433554272c4be7b94bb0e7eabd654b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6084117293357849, 'eval_accuracy': {'accuracy': 0.889}, 'eval_runtime': 21.0686, 'eval_samples_per_second': 47.464, 'eval_steps_per_second': 11.866, 'epoch': 4.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b79f28baacb4b4da6346813dd26d36e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6403375267982483, 'eval_accuracy': {'accuracy': 0.889}, 'eval_runtime': 21.087, 'eval_samples_per_second': 47.423, 'eval_steps_per_second': 11.856, 'epoch': 5.0}\n",
            "{'train_runtime': 299.7413, 'train_samples_per_second': 16.681, 'train_steps_per_second': 4.17, 'train_loss': 0.24538958206176759, 'epoch': 5.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1250, training_loss=0.24538958206176759, metrics={'train_runtime': 299.7413, 'train_samples_per_second': 16.681, 'train_steps_per_second': 4.17, 'total_flos': 556790525519424.0, 'train_loss': 0.24538958206176759, 'epoch': 5.0})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0jn1iHMyJNtM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained model predictions\n",
            "It was good. - Positive\n",
            "Not a fan, don't recommended - Negative\n",
            "Better than the first one. - Positive\n"
          ]
        }
      ],
      "source": [
        "model.to('cuda')\n",
        "print('Trained model predictions')\n",
        "for text in text_list:\n",
        "  inputs = tokenizer.encode(text, return_tensors='pt').to('cuda')\n",
        "\n",
        "  logits = model(inputs).logits\n",
        "  predictions = torch.max(logits,1).indices\n",
        "\n",
        "  print(f'{text} - {id2label[predictions.tolist()[0]]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "OQ9UjA-nLGzS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All files saved\n"
          ]
        }
      ],
      "source": [
        "output_model_file = 'pytorch_distilbert_imbd.bin'\n",
        "output_vocab_file = 'vocab_distilbert_imbd.bin'\n",
        "\n",
        "# Save model\n",
        "model_to_save = model\n",
        "torch.save(model_to_save, output_model_file)\n",
        "\n",
        "# Save tokenizer vocabulary in the current directory\n",
        "tokenizer.save_vocabulary(\".\")  # Current directory\n",
        "\n",
        "# Save model state dictionary\n",
        "torch.save(model.state_dict(), 'trained_model_gral_imbd.pth')\n",
        "\n",
        "print('All files saved')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "aplt_duke",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
